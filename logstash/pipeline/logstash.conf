input {
  file {
    type => "test_log"
    #read from package
    path => [ "/usr/share/logstash/input/*"]
    #split file by timestamp
    codec => multiline {
      patterns_dir => "/usr/share/logstash/config/pipelines/logstash-patterns"
      pattern => "^%{BASE_TIMESTAMP}"
      negate => true
      what => "previous"
    }
    exclude => [ "*.gz", "*.zip", "*.rar" ]
    start_position => "beginning"
    stat_interval => 1
    discover_interval => 10
  }
}
filter {
  grok {
    patterns_dir => "/usr/share/logstash/config/pipelines/logstash-patterns"
    #get timestamp and log body
    match => { "message" => ["%{BASE_TIMESTAMP:log_timestamp}\s%{BODY:body}"]}
   }
   date {
         match => [ "log_timestamp", "YYYY-MM-dd HH:mm:ss.SSSSSS" ]
         target => "log_timestamp_date"
       }
  kv{
    value_split => ":"
    source => "body"
  }
  kv{
    value_split => "="
    source => "body"
    field_split_pattern => "(\s+|:|[|])"
    target => "params"
  }
  mutate {
    remove_field => ["body"]
    remove_field => ["host"]
    remove_field => ["timestamp"]
  }
}
output {
  elasticsearch {
        index => "test_for_logreader"
        hosts => "elasticsearch:9200"
        #data_stream => true
    }
  stdout {
    codec => rubydebug
  }
}